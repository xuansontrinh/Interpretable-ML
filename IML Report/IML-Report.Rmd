---
title: "Interpretable Machine Learning Scope Definition Report"
author:
  - Xuan-Son Trinh^[Ludwig Maximilian University of Munich, Son.Trinh@campus.lmu.de]
  - Victor Tuekam^[Ludwig Maximilian University of Munich, t.victor@campus.lmu.de]
output:
  pdf_document:
    citation_package: default
    toc: false
    number_sections: true
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data set
For the Seminar we use the South German Credit dataset, available in the UCI Machine learning repository^[https://archive.ics.uci.edu/ml/datasets/South+German+Credit+%28UPDATE%29].

The data set consists of a 1000 observations together with 21 attributes. The data was collected between 1973 and 1975. The task associated with this data set is the classification of individuals (instances) according to their credit risk ("good", "bad").


| Attribute | Description                 |
| --------- |-----------------------------|
| status | Status of the debtor's checking account with the bank\
(factor with 4 levels: _"no checking account"_, _"... < 0 DM"_, _"0<= ... < 200 DM"_, _"... >= 200 DM / salary for at least 1 year"_) |
| duration | Credit duration in months (int) |
| credit_history | History of the compliance with previous or concurrent credit contracts\
(factor with 5 levels: _"delay in paying off in the past"_, _"critical account/other credits elsewhere"_, _"no credits taken/all credits paid back duly"_, _"existing credits paid back duly till now"_, _"all credits at this bank paid back duly"_) |
| purpose| Purpose for which the credit is needed\
(factor with 11 levels: _"others"_, _"car (new)"_, _"car (used)"_, _"furniture/equipment"_, _"radio/television"_, _"domestic appliances"_, _"repairs"_, _"education"_, _"vacation"_, _"retraining"_, _"business"_) |
| amount| Amount in DM (int) |
| savings| Debtor's savings\
(factor with 5 levels:  _"unknown/no savings account"_, _"... <  100 DM"_, _"100 <= ... <  500 DM"_, _"500 <= ... < 1000 DM"_, _"... >= 1000 DM"_) |
| employment_duration| Duration of debtor's employment with current employer\
(ordered factor with 5 levels: _"unemployed"_ < _"< 1 yr"_ < _"1 <= ... < 4 yrs"_ < _"4 <= ... < 7 yrs"_ < _">= 7 yrs"_) |
| installment_rate| Credit installments as a percentage of debtor's disposable income\
(ordered factor with 4 levels: _">= 35"_ < _"25 <= ... < 35"_ < _"20 <= ... < 25"_ < _"< 20"_) |
| personal_status_sex | Combined information on sex and marital status\
(factor with 4 levels: _"male : divorced/separated"_, _"female : non-single or male : single"_, _"male : married/widowed"_, _"female : single"_) |
| other_debtors | Is there another debtor or a guarantor for the credit?\
(factor with 3 levels: _"none"_, _"co-applicant"_, _"guarantor"_) |
| present_residence| Length of time (in years) the debtor lives in the present residence\
(ordered factor with 4 levels: _"< 1 yr"_ < _"1 <= ... < 4 yrs"_ < _"4 <= ... < 7 yrs"_ < _">= 7 yrs"_) |
| property | The debtor's most valuable property\
(factor with 4 levels: _"unknown / no property"_, _"car or other"_, _"building soc. savings agr./life insurance"_, _"real estate"_) |
| age | Age in years (int) |
| other_installment_plans | Installment plans from providers oder than the credit-giving bank\
(factor with 3 levels: _"bank"_, _"stores"_, _"none"_) |
| housing | Type of housing the debtor lives in\
(factor with 3 levels: _"for free"_, _"rent"_, _"own"_) |
| number_credits | Number of credits including the current one the debtor has (or had) at this bank\
(ordered factor with 4 levels: _"1"_ < _"2-3"_ < _"4-5"_ < _">= 6"_) |
| job | Quality of debtor's job\
(factor with 4 levels: _"unemployed/unskilled - non-resident"_, _"unskilled - resident"_, _"skilled employee/official"_, _"manager/self-empl./highly qualif. employee"_) |
| people_liable | Number of persons who financially depend on the debtor (i.e., are entitled to maintenance)\
(factor with 2 levels: _"3 or more"_, _"0 to 2"_) |
| telephone | Is there a telephone landline registered on the debtor's name?\
(factor with 2 levels: _"no"_, _"yes (under customer name)"_) |
| foreign_worker | Is the debtor a foreign worker?\
(factor with 2 levels: _"yes"_, _"no"_) |
| credit_risk | Has the credit contract been complied with (good) or not (bad)?\
(factor with 2 levels: _"bad"_, _"good"_) |


## Load data
```{r, include=FALSE}
# Load necessary libraries
library("mlr3verse")
library("ggplot2")

set.seed(11302020)
lgr::get_logger("mlr3")$set_threshold("error")
```

```{r south-german-credit}
task <- tsk("german_credit")
```
We use the `skimr` package to visualize the data distribution.
The output is not printed here, to save space. One could observe that the data set doesn't have any missing values and require little preprocessing to fit our model.
```{r, eval=FALSE}
library(skimr)
skimr::skim(task$data())
```
# Fitting some models
The `mlr3` package and other packages from the mlr3 ecosystem are used to do the modeling.
The fitted and tuned models are:
- Logistic Regression
- Decision Trees
- Random Forest
- Xgboost
- Support Vector machines (with linear, polynomial, and radial kernels)

For preprocessing, we do the following:
- Standardize numerical variables by centering them around their mean and scaling them by their root-mean-square.
- One-hot encode factor and ordered-factor variables.
- To account for the class imbalance in the data set, we perform oversample of the minority class ("bad" class).
```{r}
# PipeOps
fencoder <- po("encode",
  method = "one-hot",
  affect_columns = selector_type("factor")
)
ord_to_int <- po("colapply",
  applicator = as.integer,
  affect_columns = selector_type("ordered")
)

encoder <- fencoder %>>% ord_to_int

po_over <- po("classbalancing",
  id = "oversample", adjust = "minor",
  reference = "minor", shuffle = FALSE, ratio = 2.3
)
threshold <- po("threshold")
pos <- po("scale") %>>%
  encoder %>>% po_over
```
## Tuning and Benchmarking
The parameter tuning is done with the following settings for all models. The tuning code is available in the `.Rmd` source file.
```{r}
# tuning settings
inner_cv5 <- rsmp("cv", folds = 5L)
measure <- msr("classif.bacc")
tuner <- tnr("grid_search", resolution = 7L)
terminator <- trm("evals", n_evals = 20)
```
```{r, include=FALSE}
# Logistic regression
log_reg_learner <- lrn("classif.log_reg", predict_type = "prob")
log_reg_pipeline <- pos %>>% log_reg_learner %>>% threshold
log_reg_glearner <- GraphLearner$new(log_reg_pipeline, id = "log_reg")

log_reg_at <- AutoTuner$new(
  learner = log_reg_glearner,
  resampling = inner_cv5,
  measure = measure,
  search_space = ParamSet$new(list(ParamDbl$new("threshold.thresholds",
    lower = 0, upper = 1
  ))),
  terminator = terminator,
  tuner = tuner
)

# Regression trees
rpart_learner <- lrn("classif.rpart", predict_type = "prob")
rpart_pipeline <- pos %>>% rpart_learner %>>% threshold
rpart_glearner <- GraphLearner$new(rpart_pipeline, id = "rpart")

rpart_at <- AutoTuner$new(
  learner = rpart_glearner,
  resampling = inner_cv5,
  measure = measure,
  search_space = ParamSet$new(list(ParamDbl$new("threshold.thresholds",
    lower = 0, upper = 1
  ))),
  terminator = terminator,
  tuner = tuner
)

# Random forest
ranger_pipeline <- pos %>>% lrn("classif.ranger",
  predict_type = "prob"
) %>>% threshold
ranger_glearner <- GraphLearner$new(ranger_pipeline, id = "ranger")

ranger_tune_ps <- ParamSet$new(list(
  ParamDbl$new("threshold.thresholds", lower = 0, upper = 1),
  ParamInt$new("classif.ranger.num.trees",
    lower = 100, upper = 140
  ), # number of trees
  ParamInt$new("classif.ranger.mtry",
    lower = 1, upper = ceiling(task$ncol / 2)
  ), # number of variables to possibly split at in each node
  ParamInt$new("classif.ranger.max.depth",
    lower = 2, upper = 20
  ) # maximum depth of the tree
))

ranger_at <- AutoTuner$new(
  learner = ranger_glearner,
  resampling = inner_cv5,
  measure = measure,
  search_space = ranger_tune_ps,
  terminator = terminator,
  tuner = tuner
)

# Svms
linear_svm_learner <- lrn("classif.svm",
  type = "C-classification", kernel = "linear",
  predict_type = "prob"
)
poly_svm_learner <- lrn("classif.svm",
  type = "C-classification", kernel = "polynomial",
  predict_type = "prob"
)
radial_svm_learner <- lrn("classif.svm",
  type = "C-classification", kernel = "radial",
  predict_type = "prob"
)

# Pipelines
linear_svm_pipeline <- pos %>>% linear_svm_learner %>>% threshold
poly_svm_pipeline <- pos %>>% poly_svm_learner %>>% threshold
radial_svm_pipeline <- pos %>>% radial_svm_learner %>>% threshold

# Learners
linear_svm_glearner <- GraphLearner$new(linear_svm_pipeline, id = "linear_svm")
poly_svm_glearner <- GraphLearner$new(poly_svm_pipeline, id = "poly_svm")
radial_svm_glearner <- GraphLearner$new(radial_svm_pipeline, id = "radial_svm")

# Search spaces
poly_svm_search_space <- ParamSet$new(list(
  ParamDbl$new("threshold.thresholds", lower = 0, upper = 1),
  ParamDbl$new("classif.svm.cost", lower = 0.01, upper = 100),
  ParamDbl$new("classif.svm.gamma", lower = 0.0001, upper = 1),
  ParamInt$new("classif.svm.degree", lower = 1, upper = 4)
))

radial_svm_search_space <- ParamSet$new(list(
  ParamDbl$new("threshold.thresholds", lower = 0, upper = 1),
  ParamDbl$new("classif.svm.cost", lower = 0.01, upper = 100),
  ParamDbl$new("classif.svm.gamma", lower = 0.0001, upper = 1)
))

linear_svm_search_space <- ParamSet$new(list(
  ParamDbl$new("threshold.thresholds", lower = 0, upper = 1),
  ParamDbl$new("classif.svm.cost", lower = 0.01, upper = 100)
))

linear_svm_at <- AutoTuner$new(
  learner = linear_svm_glearner,
  resampling = inner_cv5,
  terminator = terminator,
  search_space = linear_svm_search_space,
  tuner = tuner,
  measure = measure
)
poly_svm_at <- AutoTuner$new(
  learner = poly_svm_glearner,
  resampling = inner_cv5,
  terminator = terminator,
  search_space = poly_svm_search_space,
  tuner = tuner,
  measure = measure
)
radial_svm_at <- AutoTuner$new(
  learner = radial_svm_glearner,
  resampling = inner_cv5,
  terminator = terminator,
  search_space = radial_svm_search_space,
  tuner = tuner,
  measure = measure
)
```
```{r, include=FALSE, cache=TRUE}
outer_cv3 <- rsmp("cv", folds = 3L)
design <- benchmark_grid(
  task = task,
  learners = list(
    log_reg_at,
    rpart_at,
    ranger_at,
    linear_svm_at,
    poly_svm_at,
    radial_svm_at
  ),
  resamplings = outer_cv3
)
bmr <- benchmark(design)
```

```{r}
bmr$aggregate(msr("classif.ce"))
bmr$aggregate(msr("classif.fbeta"))
bmr$aggregate(measure)
autoplot(bmr, measure = msr("classif.ce")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
autoplot(bmr, measure = msr("classif.fbeta")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
autoplot(bmr, measure = measure) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
The benchmark shows that the svm model with `radial` kernel is most performant on average. This model is a black box model.

We also observe that the performace of tree based models doesn't change significantly, when categorical variables are not coverted to numerics.

# Interpretable Machine Learning Methods and Hypotheses
We first give a brief description of some interpretable machine learning methods we would use to investigate our hypotheses. The methods are more thoroughly described in the Interpertable Machine Learning book^[https://christophm.github.io/interpretable-ml-book/].

## Interpretable Machine Learning Methods

### Feature Effects

**Partial Dependence Plot:** It shows the marginal effect a feature has on the output of a model.

**SHAP Dependence Plots:** An alternative to Partial Dependence Plot to visualize feature effects on the model output.

**SHAP Summary Plots:** Visualizes feature importance and effects in a single plot.

### Global Feature Importance

**Permutation Feature Importance:** It measures the increase in prediction error after permuting the feature values.

### Feature Interaction

**H-Statistic:** Friedman's H-Statistic can tell us two things. (1) Whether and to what extent a feature interacts with all other features in the model and (2) whether and to what extent two features interact with one-another.

### Local Interpretation Methods

**Anchors:** Provides an "anchor" explanation of individual model predictions. The "anchor" explanation is a decision rule, where-in unaccounted variables do not affect the prediction.

### Example-Based Explanations

**Counterfactual Explanations:** A counterfactual explanation of a prediction describes the smallest change to the feature values that changes the prediction to the predefined output.


## Hypotheses and Suggested IML Methods
|Hypothesis|IML Method|
|----------|----------|
|Having no `property` should imply a bad `credit_risk`|Partial Dependence Plot|
|Is being older better for `credit_risk`|Partial Dependence Plot, SHAP Dependence Plot & SHAP Summary PLot|
|Is the effect of `age` dependent on the effect of `property` on the `credit_risk` ? |H-Statistic|
|The variable `telephone` should not affect the output|SHAP Summary Plot|
|What are the most important features for the prediction of the `credit_risk`|Permutation Featurn Importance|
|Is there an interaction between `job` and `credit_history`? People with delayed `credit_history` often have low quality `job`|H-Statistic|
|What is the smallest change in `number_credits` that can toggle the model output from `good` to `bad`|Counterfactual Explanations|
|People with high quality `job`s have good `credit_risk`|SHAP Feature Importance & SHAP Summary Plots|
|How does `job` quality interact with the checking account `status` |H-Statistic|
|High number of `people_liable` associate with bad `credit_risk`|Partial Dependence Plot|
|Does `age` and `people_liable` interact ?|H-Statistic|
|Does having no `property` mean bad `credit_risk` and how does this relate to age|Anchors, H-Statistic|
|Being a foreign worker does not affect your credit risk. If this feature is important for prediction, this implies discrimination|SHAP Feature Importance & SHAP Summary Plots|
|The better the savings, the better your credit risk|Permutation Feature Importance, SHAP Feature Importance & SHAP Summary Plots|
|How does a change in the `savings` threshold change the `credit_risk`|Counterfactual Explanations|
|The higher the `installment_rate` the worse the `credit_risk`|Partial Dependence Plot, SHAP Dependence Plot & SHAP Summary Plots|
|Does owning a house (`housing`) mean good `credit_risk`|Partial Dependence Plot, SHAP Dependence Plot & SHAP Summary Plot|
