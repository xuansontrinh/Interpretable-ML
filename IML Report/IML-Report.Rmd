---
title: "Interpretable Machine Learning Scope Definition Report"
author:
  - Xuan-Son Trinh^[Ludwig Maximilian University of Munich, Son.Trinh@campus.lmu.de]
  - Victor Tuekam^[Ludwig Maximilian University of Munich, t.victor@campus.lmu.de]
output: 
  pdf_document:
    citation_package: default
    toc: false
    number_sections: true
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data set
For the Seminar we use the South German Credit dataset, available in the UCI Machine learning repository^[https://archive.ics.uci.edu/ml/datasets/South+German+Credit+%28UPDATE%29].

The data set consists of a 1000 observations together with 21 attributes. The data was collected between 1973 and 1975. The task associated with this data set is the classification of individuals (instances) according to their credit risk ("good", "bad").

| Attribute        | Description           
| ---------------- |-------------
| status         | Status of the debtor's checking account with the bank (factor) |
| duration         | Credit duration in months (int) |
| credit_history    | History of the compliance with previous or concurrent credit contracts (factor) |
| purpose| Purpose for which the credit is needed (factor) |
| amount| Amount in DM (int) |
| savings| Debtor's savings (factor) |
| employment_duration| Duration of debtor's employment with current employer (oridinal, factor) |
| installment_rate| Credit installments as a percentage of debtor's disposable income (ordinal, factor) |
| personal_status_sex | Combined information on sex and marital status (factor) |
| other_debtors | Is there another debtor or a guarantor for the credit ? (factor) |
| present_residence| Length of time (in years) the debtor lives in the present residence (oridinal, factor) |
| property | The debtor's most valuable property, (oridnal, factor) |
| age | Age in years (int) |
| other_installment_plans | Installment plans from providers oder than the credit-giving bank (factor) |
| housing | Type of housing the debtor lives in  (factor) |
| number_credits | Number of credits including the current one the debtor has (or had) at this bank (ordinal, factor) |
| job | Quality of debtor's job (ordinal, factor) |
| people_liable | Number of persons who financially depend on the debtor (i.e., are entitled to maintenance) (binary, factor) |
| telephone | Is there a telephone landline registered on the debtor's name? (binary, factor) |
| foreign_worker | Is the debtor a foreign worker ? (binary, factor) | 
| credit_risk | Has the credit contract been complied with (good) or not (bad) ? (binary, factor) |



## Load data
```{r south-german-credit}
load("../south-german-credit.Rda")
```
We use the `skimr` package to visualize the data distribution.
The output is not printed here, to save space. One could observe that the data set doesn't have any missing values and require little preprocessing to fit our model.
```{r, eval=FALSE}
library(skimr)
skimr::skim(data)
```
# Fitting a black box model (xgboost)
The `mlr3` package and other packages from the mlr3 ecosystem are used to do the modeling.

```{r, include=FALSE}
# Load necessary libraries
library(data.table)
library(mlr3)
library(mlr3viz)
library(mlr3learners)
library(mlr3extralearners)
library(mlr3tuning)
library(mlr3keras)
library(mlr3filters)

library(paradox)

library(ggplot2)
library(GGally)
library(ranger)
library(xgboost)
library(mboost)
library(e1071)
library(mltools)

lgr::get_logger("mlr3")$set_threshold("error")
```

As the `xgboost` package doesn't support handling categorical features, we do some preprocessing here to convert categorical features to numeric features.
```{r}
encode_ordinal <- function(x, order = unique(x)) {
  x <- as.numeric(factor(x, levels = order, exclude = NULL))
  x
}

data[which(sapply(data, is.ordered))] <- sapply(data[which(sapply(
  data,
  is.ordered
))], encode_ordinal)

cat_cols <- names(data)[which(sapply(data, is.factor))]
cat_cols <- cat_cols[cat_cols != "credit_risk"]
data <- data.table::as.data.table(data)
data <- one_hot(data, cols = cat_cols)
names(data) <- make.names(names(data))
int_cols <- names(data)[which(sapply(data, is.integer))]
data[, (int_cols) := lapply(.SD, as.numeric), .SDcols = int_cols]

task <- TaskClassif$new("german_credit", data,
  target = "credit_risk", positive = "good"
)

```
## Tuning and Benchmarking
```{r}
set.seed(11302020)
classif_err_measure <- msr("classif.ce")
classif_xgboost_learner <- lrn("classif.xgboost")
tuner <- tnr("grid_search", resolution = 5L)
tune_ps <- ParamSet$new(list(
  ParamDbl$new("eta", lower = 0.01, upper = 0.3), # controls the learning rate
  ParamDbl$new("colsample_bytree",
    lower = 0.5, upper = 0.9
  ), # fraction of features (variables) supplied to a tree
  ParamInt$new("max_depth",
    lower = 2, upper = 20
  ), # maximum depth of the tree
  ParamDbl$new("subsample",
    lower = 0.5, upper = 0.8
  ), # fraction of sample supplied to a tree
  ParamInt$new("nrounds",
    lower = 100, upper = 140
  ), # maximum number of iterations
  ParamDbl$new("gamma", lower = 0, upper = 5), # regularization controller
  ParamDbl$new("lambda", lower = 1, upper = 4.5), # L2 regularization
  ParamDbl$new("alpha", lower = 0, upper = 1) # L1 regularization
))
terminator <- trm("evals", n_evals = 5L)
at <- AutoTuner$new(
  learner = classif_xgboost_learner,
  resampling = rsmp("holdout"),
  measure = classif_err_measure,
  search_space = tune_ps,
  terminator = terminator,
  tuner = tuner
)
```
```{r, results="hide", warning=FALSE}
design <- benchmark_grid(
  tasks = task,
  learners = list(lrn("classif.log_reg"), lrn("classif.rpart"), at),
  resamplings = rsmp("cv", folds = 5L)
)

bmr <- benchmark(design)
```

```{r}
autoplot(bmr$filter(learner_ids = c(
  "classif.log_reg",
  "classif.rpart", "classif.xgboost.tuned"
))) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
The benchmark shows that the xgboost blackbox model is more performant on average than logistic regression and regression trees, which are interpretable models.

# Interpretable Machine Learning Methods and Hypotheses
We first give a brief description of some interpretable machine learning methods we would use to investigate our hypotheses. The methods are more thoroughly described in the Interpertable Machine Learning book^[https://christophm.github.io/interpretable-ml-book/].

## Interpretable Machine Learning Methods

### Feature Effects
  
**Partial Dependence Plot:** It shows the marginal effect a feature has on the output of a model.
  
**SHAP Dependence Plots:** An alternative to Partial Dependence Plot to visualize feature effects on the model output.

**SHAP Summary Plots:** Visualizes feature importance and effects in a single plot.

### Global Feature Importance
  
**Permutation Feature Importance:** It measures the increase in prediction error after permuting the feature values.

### Feature Interaction
  
**H-Statistic:** Friedman's H-Statistic can tell us two things. (1) Whether and to what extent a feature interacts with all other features in the model and (2) whether and to what extent two features interact with one-another.

### Local Interpretation Methods
  
**Anchors:** Provides an "anchor" explanation of individual model predictions. The "anchor" explanation is a decision rule, where-in unaccounted variables do not affect the prediction.

### Example-Based Explanations

**Counterfactual Explanations:** A counterfactual explanation of a prediction describes the smallest change to the feature values that changes the prediction to the predefined output.


## Hypotheses and Suggested IML Methods
|Hypothesis|IML Method|
|----------|----------|
|Having no `property` should imply a bad `credit_risk`|Partial Dependence Plot|
|Is being older better for `credit_risk`|Partial Dependence Plot, SHAP Dependence Plot & SHAP Summary PLot|
|Is the effect of `age` dependent on the effect of `property` on the `credit_risk` ? |H-Statistic|
|The variable `telephone` should not affect the output|SHAP Summary Plot|
|What are the most important features for the prediction of the `credit_risk`|Permutation Featurn Importance|
|Is there an interaction between `job` and `credit_history`? People with delayed `credit_history` often have low quality `job`|H-Statistic|
|What is the smallest change in `number_credits` that can toggle the model output from `good` to `bad`|Counterfactual Explanations|
|People with high quality `job`s have good `credit_risk`|SHAP Feature Importance & SHAP Summary Plots|
|How does `job` quality interact with the checking account `status` |H-Statistic|
|High number of `people_liable` associate with bad `credit_risk`|Partial Dependence Plot|
|Does `age` and `people_liable` interact ?|H-Statistic|
|Does having no `property` mean bad `credit_risk` and how does this relate to age|Anchors, H-Statistic|
|Being a foreign worker does not affect your credit risk. If this feature is important for prediction, this implies discrimination|SHAP Feature Importance & SHAP Summary Plots|
|The better the savings, the better your credit risk|Permutation Feature Importance, SHAP Feature Importance & SHAP Summary Plots|
|How does a change in the `savings` threshold change the `credit_risk`|Counterfactual Explanations|
|The higher the `installment_rate` the worse the `credit_risk`|Partial Dependence Plot, SHAP Dependence Plot & SHAP Summary Plots|
|Does owning a house (`housing`) mean good `credit_risk`|Partial Dependence Plot, SHAP Dependence Plot & SHAP Summary Plot|
